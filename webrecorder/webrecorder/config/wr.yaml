
# Sessions Durations (in seconds) -- total time and extend thresholds
session.durations:
    short:
        total: 5400
        extend: 3600

    long:
        total: 15724800
        extend: 604800

    restricted:
        total: 5400
        extend: 3600

# session settings
session.secret: $SECRET_KEY
session.key: __wr_sesh
session.key_template: 'sesh:{0}'
session.long_sessions_key: 'ls:{0}'

default_max_size: 1000000000
default_max_anon_size: 1000000000
default_max_coll: 10

skip_key_secs: 330

open_rec_ttl: 5400
max_warc_size: 500000000

max_detect_pages: 0

assets_path: ./webrecorder/config/assets.yaml

temp_prefix: 'temp-'

#browser_req_url: 'http://shepherd:9020/api/browsers/request_browser/{browser}'
#browser_list_url: 'http://shepherd:9020/api/browsers/browsers'
browser_req_url: 'http://shepherd:9020/api/request/{browser}'
browser_list_url: 'http://shepherd:9020/api/images/browser'
browser_info_url: 'http://shepherd:9020/api/flock/{reqid}'

proxy_host: 'proxy'

all_archives_index: './webarchives.yaml'
patch_archives_index: 'pkg://webrecorder/config/patch_webarchives.yaml'

# time interval for websocket status updates (in seconds)
status_update_secs: 1.0

cache_template: 'cache:{0}'

# Upstream url templates
url_templates:
    delete: '{record_host}/delete?user={user}&coll={coll}&rec={rec}&type={type}'
    rename: '{record_host}/rename?from_user={from_user}&from_coll={from_coll}&from_rec={from_rec}&to_user={to_user}&to_coll={to_coll}&to_title={to_title}&to_rec={to_rec}'

    # upload path
    upload: '{record_host}/record/$upload?param.user={user}&param.coll={coll}&param.rec={rec}&put_record=stream&param.upid={upid}'

    # core replay funcs
    live: '{live_host}/live/resource/postreq?'

    record: '{record_host}/record/live/resource/postreq?param.user={user}&param.coll={coll}&param.rec={rec}&param.ip={ip}'
    extract: '{record_host}/record/extract/resource/postreq?param.user={user}&param.coll={coll}&param.rec={rec}&param.ip={ip}&sources={sources}&inv_sources={inv_sources}&param.recorder.patch_rec={patch_rec}'
    patch: '{record_host}/record/patch/resource/postreq?param.user={user}&param.coll={coll}&filter=!status:[45][\d][\d]&param.recorder.rec={rec}&param.rec=*&param.ip={ip}'

    put_record: '{record_host}/record/live/resource/postreq?param.user={user}&param.coll={coll}&param.rec={rec}&put_record=resource'

    replay: '{replay_host}/replay/resource/postreq?param.user={user}&param.coll={coll}&param.rec={rec}'
    replay-coll: '{replay_host}/replay-coll/resource/postreq?param.user={user}&param.coll={coll}&param.rec=*'


recorder_accept_colls:
    extract: '.*'
    #patch: '(live|patch:)'
    patch: '^[^r][^:].*'
    live: 'live'


# Download paths
download_paths:
    filename: '{title}-{timestamp}.warc'

    rec: '{host}/{user}/{coll}/{rec}/$download'
    coll: '{host}/{user}/{coll}/$download'

download_chunk_encoded: false


# Misc Settings
invites_enabled: $REQUIRE_INVITES

warcsign_private_key: ./keys/wr.pem
warcsign_public_key: ./keys/wr_pub.pem

email_sender: $EMAIL_SENDER
email_smtp_url: $EMAIL_SMTP_URL

metadata:
    product: Webrecorder
    type: default

# Default Descriptions

coll_desc: ''

user_desc: |
    ## {0} archive

    Available collections are listed below.

# Default Collection created with new user
# if not migrating temp collection
default_coll:
    id: 'default-collection'
    title: 'Default Collection'
    desc: |
        *This is your first collection!*

        Each collection contains pages youâ€™ve captured using Webrecorder.

        To add to this collection you can capture more pages.

        You can make lists and add text to provide information about one or more pages in your collection.

upload_coll:
    id: 'uploaded-collection'
    title: 'Uploaded Collection'
    desc: |
        This collection was automatically created from an uploaded archive file.

        Source file: **{filename}**

        Archive software: **{software}**

        Date Created: **{datetime}**


page_detect_list:
    public: true
    title: 'Pages Detected'
    desc: |
        This list was created automatcally by guessing which URLs are web pages in this archive file.


# WARC Paths and Names
#warc_path_templ: '{user}/{coll}/{rec}/'

warc_path_templ: '{user}/'

storage_path_templ: '{today}/{coll}/{obj_type}/{filename}'

warc_name_templ: 'rec-{timestamp}-{hostname}-{random}.warc.gz'
index_name_templ: 'index-{timestamp}-{random}.cdxj'

info_index_key: '@index_file'

full_warc_prefix: 'http://nginx:6090'

local_store_prefix: 'local+http://nginx:6090'


# Redis Keys
cdxj_key_templ: 'r:{rec}:cdxj'

coll_cdxj_key_templ: 'c:{coll}:cdxj'
coll_cdxj_ttl: 1800

open_rec_key_templ: 'r:{rec}:open'

page_key_templ: 'r:{rec}:page'

info_key_templ:
    rec: 'r:{rec}:info'
    coll: 'c:{coll}:info'
    user: 'u:{user}:info'

coll_map_key_templ: 'u:{user}:colls'
rec_map_key_templ: 'c:{coll}:recs'

upload_key_templ: 'u:{user}:upl:{upid}'

tags_key: 'z:tags'
user_tag_templ: 'r:{rec}:tag:{tag}'

ra_key: 'r:{rec}:ra'

user_usage_key: 'h:user-usage'
temp_usage_key: 'h:temp-usage'

rate_limit_key: 'ipr:{ip}:{H}'

dyn_cookie_templ:
    'rec': 'r:{rec}:{id}:cookie:'
    'coll': 'c:{coll}:{id}:cookie:'

dyn_stats_key_templ:
    'rec': 'r:{rec}:{id}:stats:'
    'coll': 'c:{coll}:{id}:stats:'

dyn_ref_templ:
    'rec': 'r:{rec}:{id}:ref:'
    'coll': 'c:{coll}:{id}:ref:'

dyn_stats_secs: 330

warc_key_templ: 'r:{rec}:wk'
coll_warc_key_templ: 'c:{coll}:warc'

commit_wait_templ: 'w:{filename}'
commit_wait_secs: 30

upload_status_expire: 120

skip_key_templ: 'us:{user}:s:{url}'

del_templ:
    rec: 'r:{rec}:*'
    coll: 'c:{coll}:*'
    user: 'u:{user}:*'

storage_key_templ: 's:{name}'


# Recorder
recorder_name: 'recorder'

# Rewrite
use_js_obj_proxy: true

enable_memento: true

framed_replay: true

query_html: time_info.html


